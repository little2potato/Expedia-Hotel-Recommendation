{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import training and testing dataset\n",
    "import pandas as pd\n",
    "destinations = pd.read_csv(\"destinations.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assign unique Id and generate data feature for test and training dataset\n",
    "test_ids = set(test.user_id.unique())\n",
    "train_ids = set(train.user_id.unique())\n",
    "intersection_count = len(test_ids & train_ids)\n",
    "intersection_count == len(test_ids)\n",
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select 10000 data for our experiment\n",
    "import random\n",
    "\n",
    "unique_users = train.user_id.unique()\n",
    "\n",
    "sel_user_ids = [unique_users[i] for i in sorted(random.sample(range(len(unique_users)), 10000)) ]\n",
    "sel_train = train[train.user_id.isin(sel_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "t2 = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]\n",
    "t2 = t2[t2.is_booking == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict with common top-5 clusters\n",
    "most_common_clusters = list(train.hotel_cluster.value_counts().head().index)\n",
    "predictions = [most_common_clusters for i in range(t2.shape[0])]\n",
    "#calculate MAP@5 score\n",
    "import ml_metrics as metrics\n",
    "target = [[l] for l in t2[\"hotel_cluster\"]]\n",
    "metrics.mapk(target, predictions, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.corr()[\"hotel_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use PCA to convert 149 features to 3\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "dest_small = pca.fit_transform(destinations[[\"d{0}\".format(i + 1) for i in range(149)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "dest_small[\"srch_destination_id\"] = destinations[\"srch_destination_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate new features\n",
    "def generate_new_feature(df):\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"srch_ci\"] = pd.to_datetime(df[\"srch_ci\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    df[\"srch_co\"] = pd.to_datetime(df[\"srch_co\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    \n",
    "    props = {}\n",
    "    for prop in [\"month\", \"day\", \"hour\", \"minute\", \"dayofweek\", \"quarter\"]:\n",
    "        props[prop] = getattr(df[\"date_time\"].dt, prop)\n",
    "    \n",
    "    carryover = [p for p in df.columns if p not in [\"date_time\", \"srch_ci\", \"srch_co\"]]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "    \n",
    "    date_props = [\"month\", \"day\", \"dayofweek\", \"quarter\"]\n",
    "    for prop in date_props:\n",
    "        props[\"ci_{0}\".format(prop)] = getattr(df[\"srch_ci\"].dt, prop)\n",
    "        props[\"co_{0}\".format(prop)] = getattr(df[\"srch_co\"].dt, prop)\n",
    "    props[\"stay_span\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[h]')\n",
    "        \n",
    "    ret = pd.DataFrame(props)\n",
    "    \n",
    "    ret = ret.join(dest_small, on=\"srch_destination_id\", how='left', rsuffix=\"dest\")\n",
    "    ret = ret.drop(\"srch_destination_iddest\", axis=1)\n",
    "\n",
    "    return ret\n",
    "\n",
    "df = generate_new_feature(t1)\n",
    "df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [c for c in df.columns if c not in [\"hotel_cluster\"]]\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Random decision Forest\n",
    "clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.05)\n",
    "scores = cross_validation.cross_val_score(clf, df[predictors], df['hotel_cluster'], cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.044268287837247192"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binary classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from itertools import chain\n",
    "\n",
    "all_probs = []\n",
    "unique_clusters = df[\"hotel_cluster\"].unique()\n",
    "for cluster in unique_clusters:\n",
    "    df[\"target\"] = 1\n",
    "    df[\"target\"][df[\"hotel_cluster\"] != cluster] = 0\n",
    "    predictors = [col for col in df if col not in ['hotel_cluster', \"target\"]]\n",
    "    probs = []\n",
    "    cv = KFold(len(df[\"target\"]), n_folds=2)\n",
    "    clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "    for i, (tr, te) in enumerate(cv):\n",
    "        clf.fit(df[predictors].iloc[tr], df[\"target\"].iloc[tr])\n",
    "        preds = clf.predict_proba(df[predictors].iloc[te])\n",
    "        probs.append([p[1] for p in preds])\n",
    "    full_probs = chain.from_iterable(probs)\n",
    "    all_probs.append(list(full_probs))\n",
    "\n",
    "prediction_frame = pd.DataFrame(all_probs).T\n",
    "prediction_frame.columns = unique_clusters\n",
    "def find_top_5(row):\n",
    "    return list(row.nlargest(5).index)\n",
    "\n",
    "preds_m = []\n",
    "for index, row in prediction_frame.iterrows():\n",
    "    preds_m.append(find_top_5(row))\n",
    "\n",
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds_m, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044268287837247192"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds_m, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_key(items):\n",
    "    return \"_\".join([str(i) for i in items])\n",
    "\n",
    "match_cols = [\"srch_destination_id\"]\n",
    "cluster_cols = match_cols + ['hotel_cluster']\n",
    "groups = t1.groupby(cluster_cols)\n",
    "top_clusters = {}\n",
    "for name, group in groups:\n",
    "    clicks = len(group.is_booking[group.is_booking == False])\n",
    "    bookings = len(group.is_booking[group.is_booking == True])\n",
    "    \n",
    "    score = bookings + .3 * clicks\n",
    "    \n",
    "    clus_name = make_key(name[:len(match_cols)])\n",
    "    if clus_name not in top_clusters:\n",
    "        top_clusters[clus_name] = {}\n",
    "    top_clusters[clus_name][name[-1]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "cluster_dict = {}\n",
    "for n in top_clusters:\n",
    "    tc = top_clusters[n]\n",
    "    top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]]\n",
    "    cluster_dict[n] = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for index, row in t2.iterrows():\n",
    "    key = make_key([row[m] for m in match_cols])\n",
    "    if key in cluster_dict:\n",
    "        preds.append(cluster_dict[key])\n",
    "    else:\n",
    "        preds.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2373425517542814"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_cols = ['user_location_country', 'user_location_region', 'user_location_city', 'hotel_market', 'orig_destination_distance']\n",
    "\n",
    "groups = t1.groupby(match_cols)\n",
    "    \n",
    "def generate_exact_matches(row, match_cols):\n",
    "    index = tuple([row[t] for t in match_cols])\n",
    "    try:\n",
    "        group = groups.get_group(index)\n",
    "    except Exception:\n",
    "        return []\n",
    "    clus = list(set(group.hotel_cluster))\n",
    "    return clus\n",
    "\n",
    "exact_matches = []\n",
    "for i in range(t2.shape[0]):\n",
    "    exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "j 0\n",
      "k 0\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 1\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 2\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 3\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 4\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 5\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n",
      "l 16\n",
      "l 17\n",
      "l 18\n",
      "l 19\n",
      "k 6\n",
      "l 0\n",
      "l 1\n",
      "l 2\n",
      "l 3\n",
      "l 4\n",
      "l 5\n",
      "l 6\n",
      "l 7\n",
      "l 8\n",
      "l 9\n",
      "l 10\n",
      "l 11\n",
      "l 12\n",
      "l 13\n",
      "l 14\n",
      "l 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-bc9f297fb994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mfull_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_matches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_common_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hotel_cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-bc9f297fb994>\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(dicts)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmergeDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mmergeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def weigh(seq, weight):\n",
    "    dict = {}\n",
    "    for key in seq:\n",
    "        dict[key] = weight\n",
    "    return dict\n",
    "\n",
    "def merge(dicts):\n",
    "    result = []\n",
    "    mergeDict = {}\n",
    "    for dict in dicts:\n",
    "        for key in dict.keys():\n",
    "            if key in mergeDict.keys():\n",
    "                mergeDict[key] += dict[key]\n",
    "            else:\n",
    "                mergeDict[key] = dict[key]\n",
    "    #print mergeDict\n",
    "    #print sorted(mergeDict, key = lambda x: mergeDict[x], reverse = True)\n",
    "    for key in sorted(mergeDict, key = lambda x: mergeDict[x], reverse = True):\n",
    "        #print key, mergeDict[key]\n",
    "        result.append(key)\n",
    "    return result\n",
    "\n",
    "max_pair = None\n",
    "max_score = 0\n",
    "for i in range(0,20):\n",
    "    print 'i', i\n",
    "    for j in range(0,20):\n",
    "        print 'j', j\n",
    "        for k in range(0,20):\n",
    "            print 'k', k\n",
    "            for l in range(0,20):\n",
    "                print 'l', l\n",
    "                full_preds = [merge(tuple([weigh(exact_matches[p],i/10),weigh(preds[p], j/10),weigh(preds_m[p], k/10),weigh(most_common_clusters, l/10)]))[:5] for p in range(len(preds))]\n",
    "                score = metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], full_preds, k=5)\n",
    "                if max_score < score:\n",
    "                    max_pair = (i,j,k,l)\n",
    "                    max_score = score\n",
    "print max_pair,max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
